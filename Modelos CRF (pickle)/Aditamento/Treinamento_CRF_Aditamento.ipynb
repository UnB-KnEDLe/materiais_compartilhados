{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gpwowf_F0Wk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a353d356-4947-491a-db15-668a509d9823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn<0.24\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.7.3)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install -U 'scikit-learn<0.24'\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "e02HRRPzDiX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6fy0XFU-zo26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df298b1b-e699-4332-9b53-814d3c294468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import sklearn_crfsuite\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import sklearn\n",
        "import joblib\n",
        "import nltk\n",
        "import joblib\n",
        "\n",
        "from sklearn_crfsuite.metrics import flat_classification_report, flat_f1_score\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn_crfsuite import scorers\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_aditamento = pd.read_csv('https://raw.githubusercontent.com/brunoedcf/data_crf_training/main/aditamento_contratual.csv')"
      ],
      "metadata": {
        "id": "oYP49ky0vEV5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CRF_Aditamento():\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "    self.crf = sklearn_crfsuite.CRF(\n",
        "      algorithm = 'lbfgs',\n",
        "      c1=0.203,\n",
        "      c2=0.032,\n",
        "      max_iterations=100,\n",
        "      all_possible_transitions=True\n",
        "    )\n",
        "\n",
        "  def get_features(self, sentence):\n",
        "        \n",
        "        sent_features = []\n",
        "        for i in range(len(sentence)):\n",
        "            # print(sentence[i])\n",
        "            word_feat = {\n",
        "                # Palavra atual\n",
        "                'word': sentence[i].lower(),\n",
        "                'capital_letter': sentence[i][0].isupper(),\n",
        "                'all_capital': sentence[i].isupper(),\n",
        "                'isdigit': sentence[i].isdigit(),\n",
        "                # Uma palavra antes\n",
        "                'word_before': '' if i == 0 else sentence[i-1].lower(),\n",
        "                'word_before_isdigit': '' if i == 0 else sentence[i-1].isdigit(),\n",
        "                'word_before_isupper': '' if i == 0 else sentence[i-1].isupper(),\n",
        "                'word_before_istitle': '' if i == 0 else sentence[i-1].istitle(),\n",
        "                # Uma palavra depois\n",
        "                'word_after': '' if i+1 >= len(sentence) else sentence[i+1].lower(),\n",
        "                'word_after_isdigit': '' if i+1 >= len(sentence) else sentence[i+1].isdigit(),\n",
        "                'word_after_isupper': '' if i+1 >= len(sentence) else sentence[i+1].isupper(),\n",
        "                'word_after_istitle': '' if i+1 >= len(sentence) else sentence[i+1].istitle(),\n",
        "\n",
        "                'BOS': i == 0,\n",
        "                'EOS': i == len(sentence)-1\n",
        "            }\n",
        "            sent_features.append(word_feat)\n",
        "        return sent_features\n",
        "\n",
        "  def load(self, data_frame):\n",
        "\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "\n",
        "    for i, row in enumerate(data_frame['treated_text']):\n",
        "      self.x.append(word_tokenize(data_frame['treated_text'][i]))\n",
        "      self.y.append(data_frame['IOB'][i].split())\n",
        "\n",
        "    for i in range(len(self.x)):\n",
        "        self.x[i] = self.get_features(self.x[i])\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "\n",
        "    self.crf.fit(self.x, self.y)\n",
        "\n",
        "    joblib.dump(self.crf, \"aditamento.pkl\")\n"
      ],
      "metadata": {
        "id": "htmcn77hvEV5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CRF_Aditamento()\n",
        "model.load(df_aditamento)"
      ],
      "metadata": {
        "id": "XrWG4Ix2vEV6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "id": "JovhZu8AvEV6"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}