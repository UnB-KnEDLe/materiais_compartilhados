{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpwowf_F0Wk7"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install -U 'scikit-learn<0.24'\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "e02HRRPzDiX-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fy0XFU-zo26"
      },
      "outputs": [],
      "source": [
        "import sklearn_crfsuite\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import sklearn\n",
        "import joblib\n",
        "import nltk\n",
        "import joblib\n",
        "\n",
        "from sklearn_crfsuite.metrics import flat_classification_report, flat_f1_score\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn_crfsuite import scorers\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_licitacao = pd.read_csv('https://raw.githubusercontent.com/brunoedcf/data_crf_training/main/licitacao.csv')"
      ],
      "metadata": {
        "id": "oYP49ky0vEV5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CRF_Licitacao():\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "    self.crf = sklearn_crfsuite.CRF(\n",
        "      algorithm = 'lbfgs',\n",
        "      c1=0.099,\n",
        "      c2=0.089,\n",
        "      max_iterations=100,\n",
        "      all_possible_transitions=True\n",
        "    )\n",
        "\n",
        "  def get_features(self, sentence):\n",
        "        \n",
        "        sent_features = []\n",
        "        for i in range(len(sentence)):\n",
        "            # print(sentence[i])\n",
        "            word_feat = {\n",
        "                # Palavra atual\n",
        "                'word': sentence[i].lower(),\n",
        "                'capital_letter': sentence[i][0].isupper(),\n",
        "                'all_capital': sentence[i].isupper(),\n",
        "                'isdigit': sentence[i].isdigit(),\n",
        "                # Uma palavra antes\n",
        "                'word_before': '' if i == 0 else sentence[i-1].lower(),\n",
        "                'word_before_isdigit': '' if i == 0 else sentence[i-1].isdigit(),\n",
        "                'word_before_isupper': '' if i == 0 else sentence[i-1].isupper(),\n",
        "                'word_before_istitle': '' if i == 0 else sentence[i-1].istitle(),\n",
        "                # Uma palavra depois\n",
        "                'word_after': '' if i+1 >= len(sentence) else sentence[i+1].lower(),\n",
        "                'word_after_isdigit': '' if i+1 >= len(sentence) else sentence[i+1].isdigit(),\n",
        "                'word_after_isupper': '' if i+1 >= len(sentence) else sentence[i+1].isupper(),\n",
        "                'word_after_istitle': '' if i+1 >= len(sentence) else sentence[i+1].istitle(),\n",
        "\n",
        "                'BOS': i == 0,\n",
        "                'EOS': i == len(sentence)-1\n",
        "            }\n",
        "            sent_features.append(word_feat)\n",
        "        return sent_features\n",
        "\n",
        "  def load(self, data_frame):\n",
        "\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "\n",
        "    for i, row in enumerate(data_frame['treated_text']):\n",
        "      self.x.append(word_tokenize(data_frame['treated_text'][i]))\n",
        "      self.y.append(data_frame['IOB'][i].split())\n",
        "\n",
        "    for i in range(len(self.x)):\n",
        "        self.x[i] = self.get_features(self.x[i])\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "\n",
        "    self.crf.fit(self.x, self.y)\n",
        "\n",
        "    joblib.dump(self.crf, \"licitacao.pkl\")\n"
      ],
      "metadata": {
        "id": "htmcn77hvEV5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CRF_Licitacao()\n",
        "model.load(df_licitacao)"
      ],
      "metadata": {
        "id": "XrWG4Ix2vEV6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "metadata": {
        "id": "JovhZu8AvEV6"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}